"""
Servicio de chat para el sistema mÃ©dico
Usa Google Gemini API REST para generar respuestas basadas en datos vectorizados
"""

import os
import json
from typing import Dict, Any, List, Optional
from datetime import datetime
import requests
import re

class ChatService:
    def __init__(self):
        # Cargar variables de entorno
        from dotenv import load_dotenv
        load_dotenv()
        
        # Configurar Gemini API REST
        self.gemini_api_key = os.getenv("GEMINI_API_KEY", "AIzaSyDdK6FsPMbayQEGoffM6X1wl9L2pEKcHCc")
        self.gemini_api_url = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent"
        
        print(f"ğŸ” API Key de Gemini: {'SÃ' if self.gemini_api_key else 'NO'}")
        
        if self.gemini_api_key:
            print("ğŸ”§ Configurando Google Gemini API REST...")
            print("âœ… Google Gemini API REST configurado correctamente")
        else:
            print("âŒ No se encontrÃ³ GEMINI_API_KEY")



    def generate_response(self, question: str, context_data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Genera respuesta usando Google Gemini API REST"""
        try:
            # Crear prompt inteligente que le permita al LLM decidir
            prompt = self._create_smart_prompt(question, context_data)
            
            # Generar respuesta usando Gemini API REST
            if self.gemini_api_key:
                response = self._generate_gemini_response(prompt)
            else:
                response = "Lo siento, no hay modelos disponibles en este momento."
            
            return {
                "success": True,
                "response": response,
                "context_used": len(context_data),
                "model_used": "Google Gemini API REST" if self.gemini_api_key else "No Model",
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            print(f"âŒ Error generando respuesta: {e}")
            return {
                "success": False,
                "response": "Lo siento, hubo un error al procesar tu pregunta. Por favor, intenta de nuevo.",
                "context_used": 0,
                "model_used": "Error",
                "timestamp": datetime.now().isoformat(),
                "error": str(e)
            }

    def _create_smart_prompt(self, question: str, context_data: List[Dict[str, Any]]) -> str:
        """Crea un prompt inteligente que permite al LLM decidir cÃ³mo responder"""
        
        # Preparar contexto mÃ©dico si existe
        medical_context = ""
        if context_data:
            medical_context = self._prepare_medical_context(context_data)
        
        # Crear prompt mÃ¡s especÃ­fico y detallado para Gemini
        prompt = f"""Eres un asistente mÃ©dico inteligente. Tu trabajo es analizar la pregunta del usuario y responder de manera especÃ­fica y Ãºtil usando SOLO la informaciÃ³n mÃ©dica disponible.

PREGUNTA DEL USUARIO: {question}

"""
        
        if medical_context:
            prompt += f"""
INFORMACIÃ“N MÃ‰DICA DISPONIBLE EN LA BASE DE DATOS:
{medical_context}

INSTRUCCIONES ESPECÃFICAS:
1. SI la pregunta es sobre informaciÃ³n mÃ©dica:
   - Si preguntan "Â¿cuÃ¡ntos pacientes hay?" â†’ Responde: "Actualmente hay {len(context_data)} pacientes registrados en el sistema"
   - Si preguntan por sÃ­ntomas de un paciente especÃ­fico â†’ Busca ese paciente en la informaciÃ³n disponible y lista sus sÃ­ntomas exactos
   - Si preguntan por pacientes con ciertos sÃ­ntomas â†’ Lista los pacientes que tienen esos sÃ­ntomas segÃºn la informaciÃ³n disponible
   - Si preguntan por diagnÃ³sticos o medicamentos â†’ Usa la informaciÃ³n disponible para responder
   - SIEMPRE usa la informaciÃ³n mÃ©dica disponible para dar respuestas precisas

2. SI la pregunta NO es mÃ©dica (hora, clima, saludos, etc.):
   - Responde de manera natural sin usar informaciÃ³n mÃ©dica
   - MantÃ©n un tono conversacional y amigable

3. IMPORTANTE:
   - Responde en espaÃ±ol
   - MantÃ©n un tono profesional pero amigable
   - Si no encuentras informaciÃ³n especÃ­fica en los datos disponibles, indÃ­calo claramente
   - NO inventes informaciÃ³n que no estÃ© en los datos proporcionados

RESPUESTA:"""
        else:
            prompt += f"""
INSTRUCCIONES:
- Si la pregunta es mÃ©dica, indÃ­calo claramente y menciona que no hay informaciÃ³n mÃ©dica disponible
- Si la pregunta NO es mÃ©dica, responde de manera natural
- MantÃ©n un tono conversacional y amigable
- Responde en espaÃ±ol

RESPUESTA:"""
        
        return prompt

    def _prepare_medical_context(self, context_data: List[Dict[str, Any]]) -> str:
        """Prepara el contexto mÃ©dico de manera estructurada"""
        if not context_data:
            return "No hay informaciÃ³n mÃ©dica disponible."
        
        context_parts = []
        for i, data in enumerate(context_data[:3]):  # Limitar a 3 pacientes
            metadata = data.get('metadata', {})
            
            patient_info = f"Paciente {i+1}: {metadata.get('patient_name', 'No especificado')}"
            if metadata.get('patient_age'):
                patient_info += f", {metadata.get('patient_age')} aÃ±os"
            
            symptoms = metadata.get('symptoms_list', '[]')
            if symptoms and symptoms != '[]':
                patient_info += f", SÃ­ntomas: {symptoms}"
            
            diagnosis = metadata.get('diagnosis', '')
            if diagnosis:
                patient_info += f", DiagnÃ³stico: {diagnosis}"
            
            medications = metadata.get('medications_list', '[]')
            if medications and medications != '[]':
                patient_info += f", Medicamentos: {medications}"
            
            context_parts.append(patient_info)
        
        return "\n".join(context_parts)

    def _generate_gemini_response(self, prompt: str) -> str:
        """Genera respuesta usando Google Gemini API REST"""
        try:
            # Preparar headers y payload para la API REST
            headers = {
                'Content-Type': 'application/json',
                'X-goog-api-key': self.gemini_api_key
            }
            
            payload = {
                "contents": [
                    {
                        "parts": [
                            {
                                "text": prompt
                            }
                        ]
                    }
                ]
            }
            
            # Hacer la peticiÃ³n a la API REST
            response = requests.post(
                self.gemini_api_url,
                headers=headers,
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                
                # Extraer el texto de la respuesta
                if 'candidates' in result and len(result['candidates']) > 0:
                    content = result['candidates'][0].get('content', {})
                    parts = content.get('parts', [])
                    if parts and len(parts) > 0:
                        return parts[0].get('text', '').strip()
                
                return "No se pudo generar una respuesta."
            else:
                print(f"âŒ Error en Gemini API REST: {response.status_code}")
                print(f"ğŸ“„ Respuesta: {response.text}")
                return "Lo siento, hubo un error procesando tu pregunta."
                
        except Exception as e:
            print(f"âŒ Error en Gemini API REST: {e}")
            return "Lo siento, hubo un error procesando tu pregunta."



def test_chat_service():
    """FunciÃ³n de prueba para el servicio de chat"""
    print("ğŸ§ª Probando ChatService...")
    
    chat_service = ChatService()
    
    # Probar diferentes tipos de preguntas
    test_questions = [
        "Hola, Â¿cÃ³mo estÃ¡s?",
        "Â¿QuÃ© hora es?",
        "Â¿QuÃ© sÃ­ntomas tiene Juan PÃ©rez?",
        "Â¿CuÃ¡ntos pacientes tenemos?",
        "Gracias por tu ayuda"
    ]
    
    for question in test_questions:
        print(f"\nğŸ“ Pregunta: {question}")
        
        # Probar generaciÃ³n de respuesta
        mock_context = [{
            "metadata": {
                "patient_name": "Juan PÃ©rez",
                "patient_age": "35",
                "symptoms_list": "fiebre, tos",
                "diagnosis": "Resfriado comÃºn"
            }
        }]
        
        response = chat_service.generate_response(question, mock_context)
        print(f"ğŸ¤– Respuesta: {response['response'][:100]}...")
        print(f"ğŸ”§ Modelo usado: {response.get('model_used', 'N/A')}")
    
    print("\nâœ… Prueba de ChatService completada")

if __name__ == "__main__":
    test_chat_service()
